---
layout: archive
title: "Research"
permalink: /Research/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Integrate Multimodal Input to Offer Tailored Feedback In Robotic Tutoring
======
Robotic tutoring systems, as they stand today, exhibit a narrowed spectrum of interaction modalities. Predominantly, they deploy computer vision techniques to oversee student tasks or lean heavily on touch-based interfaces like buttons and touchscreens for direct interactions. Such restricted avenues can sometimes impede the robot's ability to fully discern a student's understanding, consequently affecting the quality of feedback dispensed.

My research, under the guidance of Nicole Salomons, revolves around a compelling proposition: the incorporation of verbal inputs into robotic feedback systems. Through an integraton of visual and verbal data inputs—capturing both the tactile engagements and the vocal expressions of students—we seek to develop a more nuanced model of student understanding. This dual-faceted approach harnesses the power of the LLM model to interpret verbal inputs, thereby enabling robots to provide feedback that is both timely and apt, enriching the overall learning experience.

Develop a Novel AAC Text Generation System Powered by Image Recognition and LLM
======
123


More research projects can be found in my [CV](../CV_P_Jiang.pdf), but they are less HCI related.
======
